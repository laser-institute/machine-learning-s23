---
title: "How to Split Data into Training and Testing Sets"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
#| include: false
```

```{r}
#| echo: false
# then load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

- Again, create a .R file --- this time in `/module-2`
- Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

- Which parts of the supervised machine learning process is most unclear?

# Code-along

## R Code

::: {.panel-tabset}

## 0

**Loading, setting up**

```{r}
#| eval: false
#| echo: true
library(tidyverse)
library(tidymodels)

gss_cat # this is built-in data, so it's loaded differently than typical data

gss_cat <- gss_cat %>% 
    mutate(is_married = as.factor(if_else(marital == "Married", 1, 0))) # as a factor

gss_cat %>% 
    count(is_married)
```

## 1

**Split data**

```{r}
#| echo: true
#| eval: false
train_test_split <- initial_split(gss_cat, prop = .80, strata = "is_married")
data_train <- training(train_test_split)
data_test <- testing(train_test_split)
```

## 2

**Engineer features**

```{r}
#| echo: true
#| eval: false
# predicting humans based on the independent effects of height and mass
my_rec <- recipe(is_married ~ age + tvhours, data = gss_cat)
```

## 3

**Specify recipe, model, and workflow**

```{r}
#| echo: true
#| eval: false
# specify model
my_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

# specify workflow
my_wf <- workflow() %>%
   add_model(my_mod) %>% 
    add_recipe(my_rec)
```

## 4

**Fit model**

```{r}
#| echo: true
#| eval: false

fit_model <- fit(my_wf, data = gss_cat)
```

## 5

**Evaluate accuracy**

```{r}
#| echo: true
#| eval: false
predictions <- predict(fit_model, gss_cat) %>% 
    bind_cols(gss_cat) %>% 
    mutate(is_married = as.factor(is_married))

predictions %>%
  metrics(is_married, .pred_class) %>%
  filter(.metric == "accuracy")
```

:::

## python code

```{python}
#| eval: false
#| echo: true

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Load and preprocess the data
starwars = pd.read_csv('path_to_starwars.csv')  # Load your data file
starwars['species_human'] = starwars['species'].apply(lambda x: 'Human' if x == 'Human' else 'Not human')

# Split data
train, test = train_test_split(starwars, test_size=0.2, random_state=42)
X_train, y_train = train[['height', 'mass']], train['species_human']
X_test, y_test = test[['height', 'mass']], test['species_human']

# Specify model and fit
clf = LogisticRegression()
clf.fit(X_train, y_train)

# Evaluate accuracy
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

# Discussion

- In the big picture, what is the use of the training data relative to the testing data?